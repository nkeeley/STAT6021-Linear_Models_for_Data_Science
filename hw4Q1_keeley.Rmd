---
title: "Homework 3, Question 1"
author: "Nicholas Keeley"
date: "8/2/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::purl()
```

## Question 1.a

*Perform all possible regressions using the regsubsets() function from the leaps package. Write down the predictors that lead to a first-order model having the best adjusted R2, mean-squared error, Mallow’s Cp, and BIC.*

```{r 1, echo=FALSE}
library(leaps)
data<-swiss
attach(data)
# Figure out n-best regression multiple linear regression models with data.
allreg <- regsubsets(Fertility~., data=data, nbest=40) # Always gives list of 28.
#summary(allreg)
#Creating data frame with statistics of interest.
best <- as.data.frame(summary(allreg)$outmat) # the location of where parameters are.
best$p <- as.numeric(substr(rownames(best),1,1))+1 # number of paramaters.
best$r2 <- summary(allreg)$rsq # r^2
best$adjr2 <- summary(allreg)$adjr2 # adjusted r^2
best$mse <- (summary(allreg)$rss)/(dim(data)[1]-best$p) # Mean squared error
best$cp <- summary(allreg)$cp # Mallow statistic
best$bic <- summary(allreg)$bic # BIC
#best[order(best$adjr2),] # 5 (1), 4 (1)
#best[order(best$cp),] # 4 (1), 5 (1)
#best[order(best$mse),] # 5 (1), 4 (1)
#best[order(best$bic),] # 4 (1) 3 (1) 5 (1)
# best
# Model the best.
MLR_best1<-lm(Fertility~Agriculture + Education + Catholic + Infant.Mortality)
#summary(MLR_best1)
MLR_best2<-lm(Fertility~Agriculture + Examination + Education + Catholic + Infant.Mortality)
#summary(MLR_best2)
```

The designated penalized-fit criteria yielded two almost equally well-fitting first-order multiple linear regression models. 

The first, shorter model was Y'= 62.10131 - 0.15462 (X1 [Agriculture]) - 0.98026 (X2 [Education]) + 0.12467 (X3 [Catholic]) + 1.07844 (X4 [Infant.Mortality]). 

The second, longer model was Y'= 66.91518 - 0.17211 (X1 [Agriculture]) - 0.25801 (X2 [Examination]) - 0.87094 (X3 [Education]) + 0.10412 (X4 [Catholic]) + 1.07705 (X5 [Infant.Mortality].

## Question 1.b

*If you have more than 1 model from your answer in part 1a, use diagnostic plots and/or hypothesis tests to decide which model is the most promising. Which model is this?*

```{r 1.b, echo=TRUE}
## Partial F-test.
anova(MLR_best1, MLR_best2) # Cannot reject the null that non-desirable predictor == 0.
summary(MLR_best2)
```

I am evaluating whether a full model with Examination as a variable or a reduced model without Examination as a variable fits the sample data better. Since I am investigating one predictor's effect on fertility, Examination, in the presence of all other variables, I could simply examine the t-statistic for that variable wtihin the full model. However, I could also conduct a partial F-test to determine if a reduced or full model fits the data better. The null hypothesis for this test would be that the Examination coefficient is 0/the regressor has no effect on fertility in the presence of the model's other variables. The alternative hypothesis is that the Examination regressor has a significant effect on fertility in the presence of the other variables. The partial F-test suggested that I cannot reject the null hypothesis, implying that the reduced model is preferable. This is corroborated by a t-test as well.

## Question 1.c

*Are there any observations that are outlying in the response variable? If yes, report the provinces.*

Standardized, studentized, and externally studentized residuals for the model were analyzed visually and mathematically against a Bonferonni-method critical value. None of the observations can reasonably be classified as outliers.

```{r 1.c, echo=TRUE}

## Standardized  residuals
res<-MLR_best1$residuals 

## Studentized residuals
student.res<-rstandard(MLR_best1) 

## Externally studentized residuals
ext.student.res<-rstudent(MLR_best1) 

par(mfrow=c(1,3))
plot(MLR_best1$fitted.values,res,main="Standardized Residuals", xlab="Fitted Values", ylab ="Residuals")
plot(MLR_best1$fitted.values,student.res,main="Studentized Residuals", xlab="Fitted Values", ylab ="Residuals")
plot(MLR_best1$fitted.values,ext.student.res,main="Externally Studentized Residuals", xlab="Fitted Values", ylab ="Residuals")

n<-47
p<-5
qt(1-0.05/(2*n), n-p-1) # Critical value of 3.522795.
```

## Question 1.d

*Are there any observations that have high leverage? If yes, report the provinces and their leverages.*

There are two observations that have high leverage: the province of La Valle, with leverage 0.31819443 and the province of V. de Geneve with a leverage of 0.45543705.

```{r 1.d, echo=FALSE}
# Creates H_ii matrix for the model, which is distance of ith observation from centroid in x space.
lev<-lm.influence(MLR_best1)$hat
lev<-sort(lev)
cutoff<-2*(p/n)
# cutoff # 0.212766
# Points 19 and 45 have H_iis of 0.31819443 0.45543705.
row_num<-seq(1,47)
data$obs<-row_num
```

## Question 1.e

*Are there any influential observations based on DFFITs? If yes, report the provinces.*

```{r 1.e, echo=FALSE}
DFFITS<-dffits(MLR_best1) 
DFFITS[abs(DFFITS)>2*sqrt(p/n)]
#         6         37         42         47 
# -1.0634259  0.9923731  0.6602376 -0.7964460 

```

The provinces of Porrentruy, Sierre, Neuchatel, and Rive Gauche appear to be influential outliers, according to a DFFITS deletion diagnostic.

## Question 1.f

*Are there any influential observations based on Cook’s Distance? If yes, report the provinces.*

```{r 1.f, echo=FALSE}
COOK<-cooks.distance(MLR_best1) 
COOK[COOK>qf(0.5,p,n-p)]
```

None of the provinces appear to be influential outliers according to the Cook's Distance deletion diagnostic.

## Question 1.g

Both Cook's Distance and DFFITS are deletion diagnostics. However, Cook's Distance measures the squared distance betwen a regression model containing an ith term and a regression model not containing the ith term, at all n points. DFFITS measures how much the predicted response changes (in standard deviations) between a model containing an ith term and a model excluding the ith term.

## Question 1.h

*Use backward selection to find the best model according to AIC. Start with the first-order model with all the predictors. What is the regression equation selected?*

```{r 1.h, echo=FALSE}

## intercept only model
regnull <- lm(Fertility~1)
## model with all predictors
regfull <- lm(Fertility~Agriculture + Education + Catholic + Infant.Mortality)
## backward elimination
step(regfull, scope=list(lower=regnull, upper=regfull), direction="backward")

```

The regression equation selected is the same as the equation chosen in 1.b: Fertility~Agriculture + Education + Catholic + Infant.Mortality.

## Question 1.i

*A co-worker of yours states the following: “If we carry out forward selection, and start with the intercept only model, the model chosen by forward selection will be the same as the model chosen by backward selection (in part 1h).” Without performing additional analysis, will you agree with your co-worker?*

I don't think my co-worker is necessarily correct. Forward selection is fundamentally different because it adds variables based on their correlation to the response variable, and whether or not the candidate model meets the required F-statistic benchmark for reducing variance. Each subsequent variable's addition is based on the previously included variables, and a partial correlation to the response variable. Backward elimination assumes a full model with all candidate variables included, and then bases variable elimination on the lowest partial F-statistic meeting an outgoing F-statistic benchmark. Because F-statistics within each search procedure are calculated in the presence of other variables, they can yield very different recommended models.

## Question 1.j

*List two limitations of automated search procedures.*

Automated search procedures don't check whether linear assumptions are met, and subsequently can't guarantee choice of an ideal model. They are also restricted to calculating first order models, rather than considering interaction effects.

```{r output, echo=FALSE}
knitr::purl("hw4Q1_keeley.Rmd")
```
